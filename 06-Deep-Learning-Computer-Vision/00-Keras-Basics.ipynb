{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Basics\n",
    "\n",
    "Welcome to the section on deep learning! We'll be using Keras with a TensorFlow backend to perform our deep learning operations.\n",
    "\n",
    "This means we should get familiar with some Keras fundamentals and basics!\n",
    "\n",
    "## Imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will use the Bank Authentication Data Set to start off with. This data set consists of various image features derived from images that had 400 x 400 pixels. You should note **the data itself that we will be using ARE NOT ACTUAL IMAGES**, they are **features** of images. In the next lecture we will cover grabbing and working with image data with Keras. This notebook focuses on learning the basics of building a neural network with Keras.\n",
    "\n",
    "_____\n",
    "More info on the data set:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
    "\n",
    "Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. variance of Wavelet Transformed image (continuous) \n",
    "2. skewness of Wavelet Transformed image (continuous) \n",
    "3. curtosis of Wavelet Transformed image (continuous) \n",
    "4. entropy of image (continuous) \n",
    "5. class (integer) \n",
    "\n",
    "## Reading in the Data Set\n",
    "\n",
    "We've already downloaded the dataset, its in the DATA folder. So let's open it up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "data = genfromtxt('../DATA/bank_note_data.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699,   0.     ],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ,   0.     ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645,   0.     ],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ,   1.     ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ,   1.     ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ,   1.     ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Test\n",
    "\n",
    "Its time to split the data into a train/test set. Keep in mind, sometimes people like to split 3 ways, train/test/validation. We'll keep things simple for now. **Remember to check out the video explanation as to why we split and what all the parameters mean!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8734  , -0.033118, -0.20165 ,  0.55774 ],\n",
       "       [ 2.0177  ,  1.7982  , -2.9581  ,  0.2099  ],\n",
       "       [-0.36038 ,  4.1158  ,  3.1143  , -0.37199 ],\n",
       "       ...,\n",
       "       [-7.0364  ,  9.2931  ,  0.16594 , -4.5396  ],\n",
       "       [-3.4605  ,  2.6901  ,  0.16165 , -1.0224  ],\n",
       "       [-3.3582  , -7.2404  , 11.4419  , -0.57113 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5691  ,  6.3465  , -0.1828  , -2.4099  ],\n",
       "       [-0.27802 ,  8.1881  , -3.1338  , -2.5276  ],\n",
       "       [ 0.051979,  7.0521  , -2.0541  , -3.1508  ],\n",
       "       ...,\n",
       "       [ 3.5127  ,  2.9073  ,  1.0579  ,  0.40774 ],\n",
       "       [ 5.504   , 10.3671  , -4.413   , -4.0211  ],\n",
       "       [-0.2062  ,  9.2207  , -3.7044  , -6.8103  ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing the Data\n",
    "\n",
    "Usually when using Neural Networks, you will get better performance when you standardize the data. Standardization just means normalizing the values to all fit between a certain range, like 0-1, or -1 to 1.\n",
    "\n",
    "The scikit learn library also provides a nice function for this.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_object = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_object.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler_object.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler_object.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we have the data scaled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.9274"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8734  , -0.033118, -0.20165 ,  0.55774 ],\n",
       "       [ 2.0177  ,  1.7982  , -2.9581  ,  0.2099  ],\n",
       "       [-0.36038 ,  4.1158  ,  3.1143  , -0.37199 ],\n",
       "       ...,\n",
       "       [-7.0364  ,  9.2931  ,  0.16594 , -4.5396  ],\n",
       "       [-3.4605  ,  2.6901  ,  0.16165 , -1.0224  ],\n",
       "       [-3.3582  , -7.2404  , 11.4419  , -0.57113 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.44850688e-01, 5.14130449e-01, 2.18194638e-01, 8.50172258e-01],\n",
       "       [6.53339968e-01, 5.82655745e-01, 9.93242398e-02, 8.17696322e-01],\n",
       "       [4.81846700e-01, 6.69377018e-01, 3.61193167e-01, 7.63368407e-01],\n",
       "       ...,\n",
       "       [4.11050776e-04, 8.63104170e-01, 2.34046756e-01, 3.74261253e-01],\n",
       "       [2.58284115e-01, 6.16029366e-01, 2.33861752e-01, 7.02643151e-01],\n",
       "       [2.65661395e-01, 2.44444278e-01, 7.20316361e-01, 7.44775785e-01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network with Keras\n",
    "\n",
    "Let's build a simple neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 13:12:02.800814: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-06 13:12:02.801861: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-06 13:12:02.824343: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-06 13:12:02.824627: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-06 13:12:03.184290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 13:12:03.519651: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-06 13:12:03.519848: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Creates model\n",
    "model = Sequential()\n",
    "# 8 Neurons, expects input of 4 features. \n",
    "# Play around with the number of neurons!!\n",
    "model.add(Dense(4, input_dim=4, activation='relu'))\n",
    "# Add another Densely Connected layer (every neuron connected to every neuron in the next layer)\n",
    "model.add(Dense(8, activation='relu'))\n",
    "# Last layer simple sigmoid function to output 0 or 1 (our label)\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit (Train) the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29/29 - 0s - loss: 0.7107 - accuracy: 0.4407 - 318ms/epoch - 11ms/step\n",
      "Epoch 2/50\n",
      "29/29 - 0s - loss: 0.6991 - accuracy: 0.3417 - 28ms/epoch - 950us/step\n",
      "Epoch 3/50\n",
      "29/29 - 0s - loss: 0.6936 - accuracy: 0.5484 - 27ms/epoch - 928us/step\n",
      "Epoch 4/50\n",
      "29/29 - 0s - loss: 0.6897 - accuracy: 0.5495 - 20ms/epoch - 692us/step\n",
      "Epoch 5/50\n",
      "29/29 - 0s - loss: 0.6876 - accuracy: 0.5495 - 18ms/epoch - 625us/step\n",
      "Epoch 6/50\n",
      "29/29 - 0s - loss: 0.6858 - accuracy: 0.5495 - 17ms/epoch - 595us/step\n",
      "Epoch 7/50\n",
      "29/29 - 0s - loss: 0.6840 - accuracy: 0.5495 - 18ms/epoch - 616us/step\n",
      "Epoch 8/50\n",
      "29/29 - 0s - loss: 0.6821 - accuracy: 0.5495 - 18ms/epoch - 627us/step\n",
      "Epoch 9/50\n",
      "29/29 - 0s - loss: 0.6797 - accuracy: 0.5495 - 18ms/epoch - 615us/step\n",
      "Epoch 10/50\n",
      "29/29 - 0s - loss: 0.6771 - accuracy: 0.5495 - 17ms/epoch - 591us/step\n",
      "Epoch 11/50\n",
      "29/29 - 0s - loss: 0.6741 - accuracy: 0.5495 - 18ms/epoch - 629us/step\n",
      "Epoch 12/50\n",
      "29/29 - 0s - loss: 0.6706 - accuracy: 0.5495 - 17ms/epoch - 595us/step\n",
      "Epoch 13/50\n",
      "29/29 - 0s - loss: 0.6667 - accuracy: 0.5495 - 18ms/epoch - 604us/step\n",
      "Epoch 14/50\n",
      "29/29 - 0s - loss: 0.6622 - accuracy: 0.5495 - 17ms/epoch - 591us/step\n",
      "Epoch 15/50\n",
      "29/29 - 0s - loss: 0.6569 - accuracy: 0.5495 - 17ms/epoch - 575us/step\n",
      "Epoch 16/50\n",
      "29/29 - 0s - loss: 0.6505 - accuracy: 0.5495 - 17ms/epoch - 579us/step\n",
      "Epoch 17/50\n",
      "29/29 - 0s - loss: 0.6430 - accuracy: 0.5495 - 16ms/epoch - 565us/step\n",
      "Epoch 18/50\n",
      "29/29 - 0s - loss: 0.6341 - accuracy: 0.5495 - 16ms/epoch - 555us/step\n",
      "Epoch 19/50\n",
      "29/29 - 0s - loss: 0.6234 - accuracy: 0.5495 - 17ms/epoch - 577us/step\n",
      "Epoch 20/50\n",
      "29/29 - 0s - loss: 0.6112 - accuracy: 0.5517 - 16ms/epoch - 562us/step\n",
      "Epoch 21/50\n",
      "29/29 - 0s - loss: 0.5984 - accuracy: 0.5919 - 18ms/epoch - 606us/step\n",
      "Epoch 22/50\n",
      "29/29 - 0s - loss: 0.5852 - accuracy: 0.6583 - 18ms/epoch - 604us/step\n",
      "Epoch 23/50\n",
      "29/29 - 0s - loss: 0.5714 - accuracy: 0.6921 - 17ms/epoch - 583us/step\n",
      "Epoch 24/50\n",
      "29/29 - 0s - loss: 0.5582 - accuracy: 0.7236 - 17ms/epoch - 590us/step\n",
      "Epoch 25/50\n",
      "29/29 - 0s - loss: 0.5448 - accuracy: 0.7301 - 17ms/epoch - 580us/step\n",
      "Epoch 26/50\n",
      "29/29 - 0s - loss: 0.5316 - accuracy: 0.7563 - 17ms/epoch - 596us/step\n",
      "Epoch 27/50\n",
      "29/29 - 0s - loss: 0.5190 - accuracy: 0.7573 - 17ms/epoch - 590us/step\n",
      "Epoch 28/50\n",
      "29/29 - 0s - loss: 0.5052 - accuracy: 0.7769 - 17ms/epoch - 595us/step\n",
      "Epoch 29/50\n",
      "29/29 - 0s - loss: 0.4919 - accuracy: 0.7998 - 17ms/epoch - 598us/step\n",
      "Epoch 30/50\n",
      "29/29 - 0s - loss: 0.4785 - accuracy: 0.8118 - 18ms/epoch - 627us/step\n",
      "Epoch 31/50\n",
      "29/29 - 0s - loss: 0.4652 - accuracy: 0.8128 - 19ms/epoch - 658us/step\n",
      "Epoch 32/50\n",
      "29/29 - 0s - loss: 0.4522 - accuracy: 0.8379 - 18ms/epoch - 608us/step\n",
      "Epoch 33/50\n",
      "29/29 - 0s - loss: 0.4394 - accuracy: 0.8466 - 19ms/epoch - 664us/step\n",
      "Epoch 34/50\n",
      "29/29 - 0s - loss: 0.4266 - accuracy: 0.8705 - 22ms/epoch - 751us/step\n",
      "Epoch 35/50\n",
      "29/29 - 0s - loss: 0.4149 - accuracy: 0.8585 - 18ms/epoch - 636us/step\n",
      "Epoch 36/50\n",
      "29/29 - 0s - loss: 0.4033 - accuracy: 0.9108 - 18ms/epoch - 638us/step\n",
      "Epoch 37/50\n",
      "29/29 - 0s - loss: 0.3912 - accuracy: 0.8977 - 17ms/epoch - 574us/step\n",
      "Epoch 38/50\n",
      "29/29 - 0s - loss: 0.3799 - accuracy: 0.9162 - 16ms/epoch - 537us/step\n",
      "Epoch 39/50\n",
      "29/29 - 0s - loss: 0.3692 - accuracy: 0.9195 - 16ms/epoch - 562us/step\n",
      "Epoch 40/50\n",
      "29/29 - 0s - loss: 0.3590 - accuracy: 0.9304 - 16ms/epoch - 562us/step\n",
      "Epoch 41/50\n",
      "29/29 - 0s - loss: 0.3490 - accuracy: 0.9314 - 16ms/epoch - 540us/step\n",
      "Epoch 42/50\n",
      "29/29 - 0s - loss: 0.3396 - accuracy: 0.9325 - 16ms/epoch - 558us/step\n",
      "Epoch 43/50\n",
      "29/29 - 0s - loss: 0.3302 - accuracy: 0.9412 - 17ms/epoch - 573us/step\n",
      "Epoch 44/50\n",
      "29/29 - 0s - loss: 0.3216 - accuracy: 0.9445 - 17ms/epoch - 594us/step\n",
      "Epoch 45/50\n",
      "29/29 - 0s - loss: 0.3137 - accuracy: 0.9402 - 17ms/epoch - 579us/step\n",
      "Epoch 46/50\n",
      "29/29 - 0s - loss: 0.3059 - accuracy: 0.9489 - 17ms/epoch - 584us/step\n",
      "Epoch 47/50\n",
      "29/29 - 0s - loss: 0.2980 - accuracy: 0.9499 - 17ms/epoch - 585us/step\n",
      "Epoch 48/50\n",
      "29/29 - 0s - loss: 0.2908 - accuracy: 0.9532 - 17ms/epoch - 577us/step\n",
      "Epoch 49/50\n",
      "29/29 - 0s - loss: 0.2841 - accuracy: 0.9543 - 18ms/epoch - 634us/step\n",
      "Epoch 50/50\n",
      "29/29 - 0s - loss: 0.2780 - accuracy: 0.9554 - 18ms/epoch - 606us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f428c2d2a60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Play around with number of epochs as well!\n",
    "model.fit(scaled_X_train,y_train,epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting New Unseen Data\n",
    "\n",
    "Let's see how we did by predicting on **new data**. Remember, our model has **never** seen the test data that we scaled previously! This process is the exact same process you would use on totally brand new data. For example , a brand new bank note that you just analyzed ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62098955, 0.75284662, 0.21900753, 0.5730998 ],\n",
       "       [0.48778602, 0.82175665, 0.09174727, 0.56211079],\n",
       "       [0.51158363, 0.77924916, 0.13830875, 0.50392598],\n",
       "       ...,\n",
       "       [0.76115065, 0.62415668, 0.27251204, 0.83616757],\n",
       "       [0.9047516 , 0.90329171, 0.03658247, 0.42267079],\n",
       "       [0.49296526, 0.86039507, 0.06714046, 0.1622583 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spits out probabilities by default.\n",
    "# model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 501us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.08654296],\n",
       "       [0.33149558],\n",
       "       [0.24184641],\n",
       "       [0.07053527],\n",
       "       [0.07917938],\n",
       "       [0.06593645],\n",
       "       [0.15803997],\n",
       "       [0.03842717],\n",
       "       [0.08182191],\n",
       "       [0.12283576],\n",
       "       [0.4393728 ],\n",
       "       [0.6977561 ],\n",
       "       [0.14990556],\n",
       "       [0.63734776],\n",
       "       [0.32856622],\n",
       "       [0.30318913],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.6629439 ],\n",
       "       [0.6278686 ],\n",
       "       [0.05625518],\n",
       "       [0.10286784],\n",
       "       [0.6598942 ],\n",
       "       [0.04567071],\n",
       "       [0.6977561 ],\n",
       "       [0.05417957],\n",
       "       [0.03502648],\n",
       "       [0.68608445],\n",
       "       [0.00678034],\n",
       "       [0.01619759],\n",
       "       [0.60208035],\n",
       "       [0.1236724 ],\n",
       "       [0.16865231],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.03255118],\n",
       "       [0.41881135],\n",
       "       [0.6407621 ],\n",
       "       [0.6977561 ],\n",
       "       [0.10980679],\n",
       "       [0.08329724],\n",
       "       [0.58913153],\n",
       "       [0.6304548 ],\n",
       "       [0.06380215],\n",
       "       [0.6977561 ],\n",
       "       [0.67706335],\n",
       "       [0.6977561 ],\n",
       "       [0.09043134],\n",
       "       [0.08805739],\n",
       "       [0.33689937],\n",
       "       [0.09305242],\n",
       "       [0.03696419],\n",
       "       [0.10166568],\n",
       "       [0.0438253 ],\n",
       "       [0.22737515],\n",
       "       [0.58427215],\n",
       "       [0.10215127],\n",
       "       [0.02935445],\n",
       "       [0.06868876],\n",
       "       [0.03757099],\n",
       "       [0.6977561 ],\n",
       "       [0.08801417],\n",
       "       [0.32301185],\n",
       "       [0.02422957],\n",
       "       [0.08767808],\n",
       "       [0.03312622],\n",
       "       [0.06292445],\n",
       "       [0.11741742],\n",
       "       [0.3535334 ],\n",
       "       [0.3125234 ],\n",
       "       [0.6246176 ],\n",
       "       [0.05571502],\n",
       "       [0.6072642 ],\n",
       "       [0.02112097],\n",
       "       [0.61068547],\n",
       "       [0.3869895 ],\n",
       "       [0.08374932],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.53746665],\n",
       "       [0.5161599 ],\n",
       "       [0.24457106],\n",
       "       [0.3932905 ],\n",
       "       [0.05300384],\n",
       "       [0.16048478],\n",
       "       [0.0133249 ],\n",
       "       [0.07549272],\n",
       "       [0.6977561 ],\n",
       "       [0.2487726 ],\n",
       "       [0.10919104],\n",
       "       [0.05319785],\n",
       "       [0.07005228],\n",
       "       [0.5482144 ],\n",
       "       [0.63088757],\n",
       "       [0.07038586],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.1493789 ],\n",
       "       [0.0560934 ],\n",
       "       [0.15530477],\n",
       "       [0.6977561 ],\n",
       "       [0.06875427],\n",
       "       [0.16685595],\n",
       "       [0.11144955],\n",
       "       [0.6977561 ],\n",
       "       [0.03859922],\n",
       "       [0.09707088],\n",
       "       [0.37655777],\n",
       "       [0.6977561 ],\n",
       "       [0.63754207],\n",
       "       [0.6977561 ],\n",
       "       [0.5317061 ],\n",
       "       [0.03521355],\n",
       "       [0.6977561 ],\n",
       "       [0.67547274],\n",
       "       [0.6977561 ],\n",
       "       [0.02198157],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.05603401],\n",
       "       [0.6370202 ],\n",
       "       [0.11557491],\n",
       "       [0.4803091 ],\n",
       "       [0.04299101],\n",
       "       [0.21221615],\n",
       "       [0.14539441],\n",
       "       [0.6977561 ],\n",
       "       [0.597293  ],\n",
       "       [0.12712485],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.0844956 ],\n",
       "       [0.11202453],\n",
       "       [0.08946696],\n",
       "       [0.0175766 ],\n",
       "       [0.11895766],\n",
       "       [0.6977561 ],\n",
       "       [0.01313403],\n",
       "       [0.13859732],\n",
       "       [0.543736  ],\n",
       "       [0.07334756],\n",
       "       [0.10152388],\n",
       "       [0.6803626 ],\n",
       "       [0.06930543],\n",
       "       [0.4884247 ],\n",
       "       [0.22252645],\n",
       "       [0.2958427 ],\n",
       "       [0.41732132],\n",
       "       [0.47882122],\n",
       "       [0.05936985],\n",
       "       [0.40623802],\n",
       "       [0.68970984],\n",
       "       [0.6977561 ],\n",
       "       [0.01056388],\n",
       "       [0.5537164 ],\n",
       "       [0.04189851],\n",
       "       [0.594522  ],\n",
       "       [0.12922001],\n",
       "       [0.11719844],\n",
       "       [0.11615051],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.59593284],\n",
       "       [0.0587336 ],\n",
       "       [0.6977561 ],\n",
       "       [0.06039737],\n",
       "       [0.03123874],\n",
       "       [0.09603012],\n",
       "       [0.23759317],\n",
       "       [0.05793849],\n",
       "       [0.1134613 ],\n",
       "       [0.6977561 ],\n",
       "       [0.07766017],\n",
       "       [0.09063593],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.19209522],\n",
       "       [0.03214855],\n",
       "       [0.14787087],\n",
       "       [0.08933439],\n",
       "       [0.6977561 ],\n",
       "       [0.08245178],\n",
       "       [0.6977561 ],\n",
       "       [0.07526606],\n",
       "       [0.6376017 ],\n",
       "       [0.6977561 ],\n",
       "       [0.02890286],\n",
       "       [0.08686738],\n",
       "       [0.6977561 ],\n",
       "       [0.060778  ],\n",
       "       [0.15245965],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.69493073],\n",
       "       [0.5894895 ],\n",
       "       [0.2656012 ],\n",
       "       [0.3326871 ],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.08556863],\n",
       "       [0.08999528],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.68513083],\n",
       "       [0.5249098 ],\n",
       "       [0.23373307],\n",
       "       [0.0688832 ],\n",
       "       [0.37845212],\n",
       "       [0.02412878],\n",
       "       [0.14924167],\n",
       "       [0.18190311],\n",
       "       [0.03894472],\n",
       "       [0.02790157],\n",
       "       [0.3869895 ],\n",
       "       [0.12540759],\n",
       "       [0.6977561 ],\n",
       "       [0.6932695 ],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.09519409],\n",
       "       [0.6462845 ],\n",
       "       [0.04823703],\n",
       "       [0.1168564 ],\n",
       "       [0.6977561 ],\n",
       "       [0.68362725],\n",
       "       [0.68072474],\n",
       "       [0.6977561 ],\n",
       "       [0.1110033 ],\n",
       "       [0.5483712 ],\n",
       "       [0.01891808],\n",
       "       [0.62561136],\n",
       "       [0.6977561 ],\n",
       "       [0.63256174],\n",
       "       [0.6977561 ],\n",
       "       [0.09980049],\n",
       "       [0.08638145],\n",
       "       [0.21039592],\n",
       "       [0.6777678 ],\n",
       "       [0.08325105],\n",
       "       [0.6977561 ],\n",
       "       [0.6920978 ],\n",
       "       [0.6977561 ],\n",
       "       [0.08462367],\n",
       "       [0.06807477],\n",
       "       [0.04899341],\n",
       "       [0.09951593],\n",
       "       [0.01562023],\n",
       "       [0.09335047],\n",
       "       [0.6977561 ],\n",
       "       [0.23222238],\n",
       "       [0.19470929],\n",
       "       [0.08717754],\n",
       "       [0.05321987],\n",
       "       [0.06958338],\n",
       "       [0.6942401 ],\n",
       "       [0.6977561 ],\n",
       "       [0.08598702],\n",
       "       [0.1240527 ],\n",
       "       [0.05860048],\n",
       "       [0.6977561 ],\n",
       "       [0.5904523 ],\n",
       "       [0.06566657],\n",
       "       [0.6912842 ],\n",
       "       [0.0934675 ],\n",
       "       [0.6977561 ],\n",
       "       [0.6623735 ],\n",
       "       [0.6977561 ],\n",
       "       [0.50574464],\n",
       "       [0.11161857],\n",
       "       [0.3314925 ],\n",
       "       [0.02756996],\n",
       "       [0.05283175],\n",
       "       [0.07874157],\n",
       "       [0.6977561 ],\n",
       "       [0.03838253],\n",
       "       [0.18154508],\n",
       "       [0.6977561 ],\n",
       "       [0.02359936],\n",
       "       [0.6977561 ],\n",
       "       [0.03203393],\n",
       "       [0.08336513],\n",
       "       [0.6977561 ],\n",
       "       [0.02613614],\n",
       "       [0.10014876],\n",
       "       [0.04695535],\n",
       "       [0.14212824],\n",
       "       [0.07459457],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.09173302],\n",
       "       [0.6977561 ],\n",
       "       [0.07801318],\n",
       "       [0.614287  ],\n",
       "       [0.6977561 ],\n",
       "       [0.01963489],\n",
       "       [0.37844938],\n",
       "       [0.12866898],\n",
       "       [0.02781823],\n",
       "       [0.06966801],\n",
       "       [0.0894593 ],\n",
       "       [0.10356357],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.05689849],\n",
       "       [0.01830807],\n",
       "       [0.5895056 ],\n",
       "       [0.62921816],\n",
       "       [0.06176539],\n",
       "       [0.1587548 ],\n",
       "       [0.13222373],\n",
       "       [0.01945055],\n",
       "       [0.13194917],\n",
       "       [0.10421177],\n",
       "       [0.6977561 ],\n",
       "       [0.10646299],\n",
       "       [0.6977561 ],\n",
       "       [0.5383314 ],\n",
       "       [0.6977561 ],\n",
       "       [0.11186057],\n",
       "       [0.03885179],\n",
       "       [0.07212088],\n",
       "       [0.01251231],\n",
       "       [0.5540418 ],\n",
       "       [0.1595386 ],\n",
       "       [0.01166941],\n",
       "       [0.07475936],\n",
       "       [0.11117504],\n",
       "       [0.16945767],\n",
       "       [0.10808856],\n",
       "       [0.18339835],\n",
       "       [0.6977561 ],\n",
       "       [0.18703353],\n",
       "       [0.5925606 ],\n",
       "       [0.6977561 ],\n",
       "       [0.5547543 ],\n",
       "       [0.6977561 ],\n",
       "       [0.05354164],\n",
       "       [0.6503867 ],\n",
       "       [0.6977561 ],\n",
       "       [0.05846762],\n",
       "       [0.6977561 ],\n",
       "       [0.6246397 ],\n",
       "       [0.0767533 ],\n",
       "       [0.14166553],\n",
       "       [0.48740152],\n",
       "       [0.14056586],\n",
       "       [0.05764387],\n",
       "       [0.6716746 ],\n",
       "       [0.12136216],\n",
       "       [0.6977561 ],\n",
       "       [0.02713809],\n",
       "       [0.6656706 ],\n",
       "       [0.68498325],\n",
       "       [0.03896325],\n",
       "       [0.0485725 ],\n",
       "       [0.6977561 ],\n",
       "       [0.1253458 ],\n",
       "       [0.15137182],\n",
       "       [0.10372044],\n",
       "       [0.01129594],\n",
       "       [0.01697975],\n",
       "       [0.0914496 ],\n",
       "       [0.6977561 ],\n",
       "       [0.12925617],\n",
       "       [0.09338082],\n",
       "       [0.6977561 ],\n",
       "       [0.37511268],\n",
       "       [0.08694408],\n",
       "       [0.20091428],\n",
       "       [0.06256697],\n",
       "       [0.6895371 ],\n",
       "       [0.6977561 ],\n",
       "       [0.07182036],\n",
       "       [0.6977561 ],\n",
       "       [0.06394617],\n",
       "       [0.6977561 ],\n",
       "       [0.6350985 ],\n",
       "       [0.54944676],\n",
       "       [0.09065082],\n",
       "       [0.6715336 ],\n",
       "       [0.27005738],\n",
       "       [0.0960938 ],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.05794396],\n",
       "       [0.6977561 ],\n",
       "       [0.08336496],\n",
       "       [0.09365125],\n",
       "       [0.11459137],\n",
       "       [0.6977561 ],\n",
       "       [0.6977561 ],\n",
       "       [0.4315684 ],\n",
       "       [0.05539857],\n",
       "       [0.13904357],\n",
       "       [0.01678936],\n",
       "       [0.08162636],\n",
       "       [0.6977561 ],\n",
       "       [0.06363977],\n",
       "       [0.05093542],\n",
       "       [0.6977561 ],\n",
       "       [0.6867158 ],\n",
       "       [0.6283785 ],\n",
       "       [0.6977561 ],\n",
       "       [0.10438546],\n",
       "       [0.6841147 ],\n",
       "       [0.09952311],\n",
       "       [0.09273463],\n",
       "       [0.6417864 ],\n",
       "       [0.42367977],\n",
       "       [0.1309555 ],\n",
       "       [0.6977561 ],\n",
       "       [0.19545883],\n",
       "       [0.5845661 ],\n",
       "       [0.0965802 ],\n",
       "       [0.04763795],\n",
       "       [0.05052334],\n",
       "       [0.6977561 ],\n",
       "       [0.5532237 ],\n",
       "       [0.04011723],\n",
       "       [0.09890319],\n",
       "       [0.09008858],\n",
       "       [0.6977561 ],\n",
       "       [0.0509674 ],\n",
       "       [0.08786726],\n",
       "       [0.69045544],\n",
       "       [0.04466905],\n",
       "       [0.02137346],\n",
       "       [0.0912477 ],\n",
       "       [0.06029116],\n",
       "       [0.63937193],\n",
       "       [0.03703589],\n",
       "       [0.6977561 ],\n",
       "       [0.00599004],\n",
       "       [0.37844938],\n",
       "       [0.6977561 ],\n",
       "       [0.05504739],\n",
       "       [0.09563002],\n",
       "       [0.08711522],\n",
       "       [0.00703846],\n",
       "       [0.00758308],\n",
       "       [0.05044161],\n",
       "       [0.6878272 ],\n",
       "       [0.58385926],\n",
       "       [0.10999598],\n",
       "       [0.078076  ],\n",
       "       [0.06151388],\n",
       "       [0.00698652],\n",
       "       [0.14787087]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Model Performance\n",
    "\n",
    "So how well did we do? How do we actually measure \"well\". Is 95% accuracy good enough? It all depends on the situation. Also we need to take into account things like recall and precision. Make sure to watch the video discussion on classification evaluation before running this code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 690us/step - loss: 0.2692 - accuracy: 0.9492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2692055106163025, 0.9492273926734924]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=scaled_X_test,y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 489us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CV_with_python/.venv/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/CV_with_python/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    232\u001b[0m     {\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    243\u001b[0m ):\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/CV_with_python/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.99      0.97       257\n",
      "        1.0       0.98      0.92      0.95       196\n",
      "\n",
      "avg / total       0.96      0.96      0.96       453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Models\n",
    "\n",
    "Now that we have a model trained, let's see how we can save and load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myfirstmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = load_model('myfirstmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You now know how to preprocess data, train a neural network, and evaluate its classification performance!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
